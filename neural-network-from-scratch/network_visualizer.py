"""
Visualiseur simple du rÃ©seau (sans matplotlib pour Ã©viter les dÃ©pendances)
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'scripts'))

import numpy as np
from network import Network
from layers import FullyConnectedLayer, ActivationLayer
from activation_functions import Sigmoid
from loss_functions import MeanSquaredError

def print_network_architecture(network):
    """Afficher l'architecture du rÃ©seau en ASCII"""
    print("ğŸ—ï¸ ARCHITECTURE DU RÃ‰SEAU")
    print("=" * 40)
    
    layer_info = []
    for i, layer in enumerate(network.layers):
        if hasattr(layer, 'weights'):
            input_size, output_size = layer.weights.shape
            layer_info.append(f"FC({input_size}â†’{output_size})")
        elif hasattr(layer, 'activation_function'):
            func_name = layer.activation_function.__class__.__name__
            layer_info.append(f"Act({func_name})")
    
    # Affichage ASCII
    print("Input")
    for i, info in enumerate(layer_info):
        print("  â†“")
        print(f"Layer {i+1}: {info}")
    print("  â†“")
    print("Output")
    print()

def visualize_weights_ascii(network):
    """Visualiser les poids en ASCII"""
    print("âš–ï¸ VISUALISATION DES POIDS")
    print("=" * 40)
    
    layer_num = 1
    for i, layer in enumerate(network.layers):
        if hasattr(layer, 'weights'):
            print(f"\nğŸ”— Couche {layer_num} - Poids:")
            weights = layer.weights
            
            # Normaliser pour l'affichage
            w_min, w_max = weights.min(), weights.max()
            if w_max != w_min:
                weights_norm = (weights - w_min) / (w_max - w_min)
            else:
                weights_norm = weights
            
            # Affichage ASCII
            chars = " .-+*#"
            for row in weights_norm:
                line = ""
                for val in row:
                    char_idx = int(val * (len(chars) - 1))
                    line += chars[char_idx] + " "
                print(f"   {line}")
            
            print(f"   Min: {w_min:.3f}, Max: {w_max:.3f}")
            layer_num += 1

def trace_forward_pass(network, input_data):
    """Tracer une passe avant Ã©tape par Ã©tape"""
    print("ğŸ” TRACE DE LA PROPAGATION AVANT")
    print("=" * 50)
    
    current_data = input_data
    print(f"ğŸ“¥ EntrÃ©e: {current_data.flatten()}")
    
    for i, layer in enumerate(network.layers):
        if hasattr(layer, 'weights'):
            # Couche fully connected
            output = layer.forward_propagation(current_data)
            print(f"ğŸ”— Couche FC {i+1}: {current_data.flatten()} â†’ {output.flatten()}")
            current_data = output
        elif hasattr(layer, 'activation_function'):
            # Couche d'activation
            output = layer.forward_propagation(current_data)
            func_name = layer.activation_function.__class__.__name__
            print(f"âš¡ Activation {func_name}: {current_data.flatten()} â†’ {output.flatten()}")
            current_data = output
    
    print(f"ğŸ“¤ Sortie finale: {current_data.flatten()}")
    return current_data

def analyze_trained_network():
    """Analyser un rÃ©seau entraÃ®nÃ©"""
    print("ğŸ”¬ ANALYSE DÃ‰TAILLÃ‰E DU RÃ‰SEAU ENTRAÃNÃ‰")
    print("=" * 60)
    
    # CrÃ©er et entraÃ®ner le rÃ©seau
    x_train = np.array([[[0, 0]], [[0, 1]], [[1, 0]], [[1, 1]]])
    y_train = np.array([[[0]], [[1]], [[1]], [[0]]])
    
    network = Network()
    network.add_layer(FullyConnectedLayer(2, 4))
    network.add_layer(ActivationLayer(Sigmoid()))
    network.add_layer(FullyConnectedLayer(4, 1))
    network.add_layer(ActivationLayer(Sigmoid()))
    network.set_loss_function(MeanSquaredError())
    
    print("ğŸ”„ EntraÃ®nement en cours...")
    network.fit(x_train, y_train, epochs=2000, learning_rate=0.5, verbose=False)
    print("âœ… EntraÃ®nement terminÃ©!\n")
    
    # Analyser l'architecture
    print_network_architecture(network)
    
    # Visualiser les poids
    visualize_weights_ascii(network)
    
    # Tracer quelques exemples
    print("\n" + "="*50)
    test_cases = [
        np.array([[[0, 0]]]),
        np.array([[[0, 1]]]),
        np.array([[[1, 0]]]),
        np.array([[[1, 1]]])
    ]
    
    for i, test_case in enumerate(test_cases):
        print(f"\nğŸ“‹ Test case {i+1}:")
        result = trace_forward_pass(network, test_case)
        expected = y_train[i].flatten()[0]
        predicted_class = 1 if result.flatten()[0] > 0.5 else 0
        print(f"   Attendu: {expected}, PrÃ©dit: {predicted_class} {'âœ…' if predicted_class == expected else 'âŒ'}")

if __name__ == "__main__":
    analyze_trained_network()
